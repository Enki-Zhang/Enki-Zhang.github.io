---
title: 项目
top: false
cover: false
toc: true
mathjax: true
date: 2023-08-21 17:48:42
password:
summary:
tags:
categories:
---

### 如何准备项目 写在前面

首先要明白公司要什么样的人：（招聘的目的）
扎实的基础知识。优秀的编程能力（知识变现的能力）。好的学习能力

做题：先写 todo 搭框架
再写步骤，然后写细节

学习基础，在项目中怎么用，原理，应用和类似应用的区别
https://mp.weixin.qq.com/s/PsJb32dS-1IbMLeN-7j_BQ

![Alt text](image-38.png)

### 自我介绍

面试官您好，我是 2024 届计算机专业的硕士研究生，本科就读于 安徽工程大学的软件工程专业，硕士就读于 汕头大学的计算机技术 专业。在本科阶段和研究生阶段我获得过多次奖学金并通过了六级考试，同时发表了一篇 sci 论文，在专业知识方面我深入了解过 Java 集合并发编程，MySQL、Redis 等相关的内容，今年的六月到九月我在亚信科技做过 Java 开发实习生的工作（实习经历），所在部门负责中国移动 APP 拉端搜索相关业务的开发，之前还做过一个关于学生购票方面的项目。在简历投递之前我了解到咱们公司是行业领先的企业管理软件及电子商务应用解决方案供应商，拥有强大的创新能力和丰富的业务经验，对此我非常希望能够得到在这里学习和成长的机会，并继续从事 Java 开发方向的工作。那么这里的我的自我介绍完毕。

### 讲一下项目的整体，从设计思路、背景、框架、流程、核心技术、完成的工作、哪方面技术做的比较困难或者比较好这些方面来整体讲一下

![asset_img](八股-项目/2023-10-16-22-54-27.png)
架构图
https://tianweichang.blog.csdn.net/article/details/120170388?spm=1001.2101.3001.6650.14&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-120170388-blog-128361733.235%5Ev38%5Epc_relevant_anti_vip_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-120170388-blog-128361733.235%5Ev38%5Epc_relevant_anti_vip_base&utm_relevant_index=15

## 项目描述

这是一个模拟了高并发场景的抢票系统，它具备登陆和抢购的功能，并在经过几个版本的迭代之后成为支持高并发的抢票系统。为了解决用户抢购场景下的高并发问题。引入了 redis 作为缓存中间件，主要作用是 完成 sessionID 的共享，缓存预热、预减库存等等。针对抢购进行了接口限流 、redis 预减库存，消息队列异步消费，请求路径动态创建等优化。通过 Jmeter 压力测试，系统的 QPS 从 150/s 提升到 2000/s。

### Redis 预减库存

主要思路减少对数据库的访问，不需要直接访问数据库，当高并发请求到来的时候，大量的读取数据有可能会导致数据库的崩溃

1. 系统初始化的时候，将商品库存加载到 Redis 缓存中保存
2. 收到请求的时候,先在 Redis 中拿到该商品的库存值，进行库存预减，如果减完之后库存不足，直接返回逻辑 Exception 就不需要访问数据库再去减库存了，如果库存值正确，进行下一步
   将请求入队，立即给前端返回一个值，表示正在排队中，然后进行下单逻辑，后端队列进行下单，前端轮询后端发来的请求，如果秒杀成功，返回秒杀，成功，不成功就返回失败。

### 数据一致性

- 分为更新缓存

  - 更新数据库后再更新缓存
    线程 A 将数据库中 1->2 线程 B 将 2->3 当线程 A 更新数据库后，此时线程 B 继续尝试更新，但 B 线程更新速度较快使得 A 线程未结束时缓存已经更新为 3,此时 A 线程尝试更新缓存错误的将 3 变更为 2；造成缓存数据不一致
  - 先更新缓存再更新数据库
    线程 A 先将缓存改变为 2，此时线程 B 会再线程 A 走到数据库之前进行更新，将缓存改为 3，数据库改为 3，此时线程 A 来到数据库中修改数据为 2,即最终缓存为 2，数据库为 3，数据不一致；

- 删除缓存

  - 先删除缓存再更新数据库，再查询的时候去更新缓存
    线程 A 先删除缓存，后去到数据库中还未更新，此时线程 B 已经拿到了旧的数据并更新到了缓存中去，当 A 线程更新数据库完毕后,缓存和数据库已经不一致；
  - 先删除缓存在更新数据库，在删除缓存
    称之为延迟双删，在读线程写入到缓存中之后，在删除一次缓存，但有时候第二次删除可能在读线程写入缓存的前面，致使二次删除无效，因此，二次删除需要延迟进行并确保在读请求写入缓存之后进行。
  - 先更新数据库，再删除缓存，在查询的时候去更新缓存
    此时在更新数据和查询数据的间隙中可能会出现短暂缓存不一致问题。

应该：写操作执行时先操作数据库在删除缓存 ，当查询时缓存为空需要从数据库中读取并更新缓存
先写缓存再写数据库 后写的数据会产生脏数据

**修改内容时间：** 2023 年 12 月 30 日

---

下单保证原子性
开启 Spring 事务功能

2. 用户的登陆时登陆失败问题

### Spring 事务失效

方法不是 public @Transactional 只能用于 public 的方法
异常被手动捕获，未抛出不能回滚
注解所在的类是否被 spring 管理
同一个类中调用其他方法 在类上加上 Transactional 注入自己

### 接口限流

防止同一用户对单个接口进行重复调用，这里我们就需要使用到@AccessLimit 进行流量控制并搭配 springboot 的拦截器使用。

## 秒杀系统

### 用户登录验证

JWT 是一种基于 token 的认证流程实现，主要结合 SpringSecurity 生成 token

- 客户端向服务器端发送用户名和密码
- 服务器端验证通过后，在当前会话（session）中保存相关数据，比如说登录时间、登录 IP 等。
- 服务器端向客户端返回一个 session_id，客户端将其保存在 Cookie 中。
- 客户端再向服务器端发起请求时，将 session_id 传回给服务器端。
- 服务器端拿到 session_id 后，对用户的身份进行鉴定

> 使用 JWT 和 Session 的区别
> JWT 需要每次请求的时候验证一次，并且只要 JWT 没有过期，哪怕服务器端重启了，认证仍然有效。
> Session 在没有过期的情况下是不需要重新对用户信息进行验证的，当服务器端重启后，用户需要重新登录获取新的 Session

### 登录存活 Http 无状态 用户进行登录后如何完成支付

> ? 例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

- cookie 中
- 基于 token 的登录校验：在用户登录时将 token 写到 redis 中，并将 token 返回，前端通过 axios 拦截器将 token 放入到请求头中，当前用户每次请求都会携带请求头信息，服务器在根据请求头对 redis 进行验证。也可以将 token 放在 cookie 中不过 cookie 中并不安全 并且 cookie 中存在大小限制一般是 4kb

## 缓存问题

### 缓存穿透的解决方案有哪些？

缓存穿透是指 请求的数据在 redis 和 数据库中都不存在，大量的请求会直接打到数据库中
解决的方法：

- 缓存 null 值
- 布隆过滤
- 增强 id 的复杂度，避免被猜测 id 规律
- 做好数据的基础格式校验
- 加强用户权限校验
- 做好热点参数的限流

### 缓存击穿问题

热点 key 失效问题，高并发访问的 key 失效，大量的访问请求达到了数据库
方法：

1. 缓存预热：在项目中先将商品信息在项目启动时便加载到 redis 中；
   实现方式：
   秒杀 controller 中实现 InitializingBean 方法会在 Bean 初始化后将商品对应的库存缓存到 redis 中。Springboot 的 Bean 的默认作用域是单例的，因此会在项目启动时加载初始化 Bean
2. 互斥锁 使用 Redission 互斥锁，每个线程的请求均需要拿到锁，这样保存线程一次只有一个线程来请求数据，不会出现大量请求失效的问题。但是使用互斥锁的项目性能不能保证，会降低系统的吞吐量。
3. 逻辑过期
4. 热点 key 永不过期 实际上热点数据是商品的信息，当商品过期也就意味着缓存中的数据没有意义，因此设置热点 key 过期时间和秒杀过期时间一致
5. 在缓存上实现接口限流
   在秒杀接口等重要接口上做好限流策略，同时使用缓存预减库存即使判断数据库存，快速失败。

### 缓存雪崩问题及解决思路

缓存雪崩是指在同一时段大量的缓存 key 同时失效或者 Redis 服务宕机，导致大量请求到达数据库，带来巨大压力。

解决方案：

- 每次秒杀请求的路径进行随机初始化，方式用户恶意刷单
- 给不同的 Key 的 TTL 添加随机值，
- 利用 Redis 集群提高服务的可用性
- 给缓存业务添加降级限流策略
- 给业务添加多级缓存

### 如果 redis 预减库存成功，后边下单失败，怎么保证 redis 和 mysql 的一致性呢

mq 事务性消息，保证同时成功失败

### 登录使用 JWT

**JWT**:
以 json 为载体将信息进行安全封装并传递

- 作用：JWT 最常见的场景就是授权认证，一旦用户登录，后续每个请求都将包含 JWT,系统在每次处理用户请求的之前，都要先进行 JWT 安全校验，通过之后再进行处理。
  组成：`"token": 
"Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJ1c2VyIiwiaWF0IjoxNjkyNjkwNTY2LCJleHAiOjE2OTI2OTIzNjZ9.jL468EdvkxQHuCo3V2ydkTWeR8dbfoP1rAvIVlHXQPUCIqP-dQ2HSqPRPv9PXszhRE4ku7B3A7vxiI4llZyJCw",`由.分割为三部分当用户下次在进行登陆是携带 token 并后台解析进行判断。
  生成的 token 直接存放在前端
  优势：自然是服务端不需要维护一个登陆表了，节省空间，特别是用户多的情况
  无状态
  缺点：
  因为是无状态的不能够随时注销，这样点 session 可以
  ![asset_img](八股-项目/2023-08-21-18-08-42.png)
  登陆：
  自定义登陆接口 认证通过生成 JWT 将用户信息存入 Redis
  自定义 user DetailService 中实现数据库
  校验：
  定义 JWT 认证过滤器
  获取 token
  将 token 存入到客户端中的，需要客户端保存好就行，无论什么保持方式，甚至你让用户写纸条揣兜里都可以！

### 项目中的 AOP 思想的体现

使用过滤器和拦截器以及 log 日志记录

### RabbitMq 异步下单

执行流程：

1. 系统初始化将商品数量加载到 Redis 中
2. 后端收到秒杀请求后，先在 redis 中预减库存，提前判断如果库存数量不足则返回秒杀失败，从而直接截断了后续请求。
3. 否则判断这个秒杀订单是否形成，判断是否已经秒杀到了，避免一个账户秒杀多个商品
4. 秒杀单形成并且库存充足无重复秒杀，将秒杀请求封装后放入消息队列，同时返回前端秒杀标识 ，前端接收到数据后，显示排队中，并根据商品 id 轮询请求服务器（200ms 轮询一次。
5. 后端 RabbitMQ 监听秒杀 MIAOSHA_QUEUE 的这个名字的通道，如果有消息过来就获取到传入的信息，执行真正的秒杀之前，要判断数据库的库存，判断是否重复秒杀，然后执行秒杀事务（秒杀事务是一个原子操作：库存减 1，下订单、写入订单详情）

**秒杀中出现的问题**![asset_img](java面试准备/2023-08-18-16-51-58.png)

执行秒杀事务的时候，先生成订单详情，然后生成秒杀订单，为了进一步确保秒杀过程中一个用户只能秒杀一件商品，可以给秒杀订单表 miaosha_order 添加一个唯一索引，如果再次插入相同的 user_id 与 goods_id，那么将不会被允许，从而在事务中插入失败而回滚：

### 秒杀库存如何防止超卖

扣减库存时候，要保证数据库中的字段值不能为负数，

1. 通常在扣减库存的场景下使用行级锁，通过数据库引擎本身对记录加锁的控制，保证数据库的更新的安全性，并且通过 where 语句的条件，保证库存不会被减到 0 以下。意思是在 sql 语句对数据库进行操作时候进行控制。
2. 通过对库存字段设置为无符号型 那么出现负数则报错。

#### 秒杀的 ABA 问题

### 秒杀系统的设计

1.秒杀页面静态，将活动页面缓存到 redis 中，用户浏览商品等常规操作不会请求到服务端。只有到了秒杀时间点且用户点了秒杀按钮才允许访问服务端，这样处理能过滤掉绝大多数的无效请求

### 流程

将参与秒杀的商品缓存到 redis 中，并设置内存标记每个商品是否有库存，当用户点击秒杀按钮是前端发送请求，后端根据每位用户生成唯一的秒杀路径，并存入到 redis 中，前端将路径进行拼接为新的 url，发送给后端并进行路径校验，进行秒杀，先查询内存标记有库存在查询 redis 进行预减，当 redis 库存小于 0 后，返回失败，否则将请求放入到消息队列中进行排队，从队列中取出订单并更新数据库，创建订单并完成秒杀。

### 限流

- 接口限流
  拦截器拦截请求，用户每点击一次请求按钮，都会在用户 id 的缓存请求 key 中记录访问次数，查看是否有接口限流的注解，得到限流信息，并提取 request 的请求地址和用户 id 和访问路径组合为 key 作为用户的唯一标示符，value 为访问次数，通过查询访问次数是否合法来决定是否对请求进行放行，

### 分布式 session 实现

用户登录成功之后，给这个用户生成一个 sessionId(用 token 来标识这个用户)，并写到 cookie 中传递给客户端；然后客户端在随后的访问中，都在 cookie 中传递这个 token，服务端拿到这个 token 之后，就根据这个 token 来取得对应的 session 信息（token 利用 uuid 生成）

### 登录密码的加盐加密

防止查表法和彩虹表攻击 在密码中混入随机字符（加盐）生成随机盐值混入密码中，使得每次相同的密码得到不同的哈希值，盐值和密码应该放在服务器中存放在用户对应的数据库中

### 接口设计

- 参数校验
  GET 请求参数会在 URL 中 使用 requestParam/PathVariable 传递参数
  POST、PUT 向服务器提交数据 参数在请求体中使用 requestBody 传递参数

### 流量削峰

- 消息队列
- 用户答题 填写验证码 延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰
-

### 系统缓存

- 页面缓存+URL 缓存+对象缓存
  页面缓存 减少服务器压力 直接访问 redis
- 用户信息缓存 更新用户需要保证数据一致性问题 先更新数据库在修改 redis

### 问题

缓存一致性问题
先更新数据库在更新缓存
修改 token 关联的对象以及 id 关联的对象，先更新数据库后删除缓存，不能直接删除 token，删除之后就不能登录了，再将 token 以及对应的用户信息一起再写回缓存里面去

- 缓存穿透 对这些不存在的数据缓存一个空数据，对这类请求进行过滤
- 缓存击穿 使用互斥锁，只有拿到这把互斥锁的线程可以进数据库请求数据，其他线程等待，待该线程查到数据存入缓存后其他线程直接使用缓存中的数据
- 缓存雪崩 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存 及时更新用户缓存

- 消息队列 用户的请求，服务器接收后，首先写入消息队列，秒杀业务
  假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

### 唯一 ID 一人一单

在分布式情况下使用 setnx 操作对下单进行加锁，并在
使用 redis 的 setnx(只有在键不存在时才会执行存储操作)，同时增加过期时间防止死锁，当线程进行操作是判断是否有其他线程获取锁，没有则执行，否则等待

- 问题
  存在分布式锁误删问题，当 a 线程阻塞并是的分布式锁超时删除，B 线程拿到锁后 a 线程会将锁进行误删，此时需要在线程中加入线程标识，每次删除锁需要对线程进行判断防止误删。最后使用 Lua 脚本对加锁和解锁做原子操作

---

### 如何解决超卖问题

关键在与扣减库存是否多线程出问题：

1. sql 语句扣减库存时候使用乐观锁办法，判断库存数量是否>0,加上行级锁但性能较低，该如何解决。不推荐使用
2. 利用 redis 的 incr、decr 的原子性 + 异步队列
   内存标记并预减库存
   超卖现象是多线程安全问题，使用乐观锁

#### 预减库存 \*\*

使用 Redis 预减库存主要是为了做什么呢,就是它能解决什么问题
主要目的减少对数据库的访问,可以拦截卖完了之后多余的请求，防止多个请求不断达到数据库造成压力，同时不需要考虑库存数据一致性
实现思路：

1. 先将商品信息加载到 Redis 缓存中
2. 当收到秒杀请求时，在访问 Redis 之前先在内存标记中获取对应商品的库存数量，做到不需要对 Redis 进行访问就得到了库存，减少了高并发下的 Redis 压力，再判断 Redis 中的缓存商品数量预减并判断是否足够，不足则直接返回异常，并标记内存库存不足。
3. 否则将订单信息发送到消息队列中，并返回前端成功标志，之后队列消费依次创建秒杀订单完成秒杀，前端进行轮询判断是否秒杀成功。

### 减库存出现的数据不一致问题

先删除缓存，再更新数据库 会出现脏数据
如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
**应该先操作数据库再删除缓存**
采用延迟双删的思路

#### 高并发 减少数据库访问

- 预减少库存，秒杀地址隐藏，使用内存标记

- redis 的预见库存 防止大量的请求，请求到数据库中
  先对每个商品进行 hashMap 内存标记，标记是否还有库存剩余，扣减库存时候 先查询内存标记，如果为 FALSE 直接返回，不需要查数据库查询 redis 的商品库存，先对该商品进行减少，库存数小于 0 是则不需要访问数据库 直接返回失败

### 接口地址隐藏 防止根据秒杀的链接提前秒杀

只有秒杀时候再将秒杀的 url 地址通过 UUID 拼接数字，随机生成地址并缓存在 redis 中并发给前端，前端请求过来后验证秒杀的路径，通过再执行秒杀。

### 分布式锁

实现分布式情况下多线程互斥效果，为了防止超卖和重复下单 当线程过来请求
利用 SetNx 添加过期时间防止死锁，但是过期时间如何评估，
分布式锁误删：
（a 线程阻塞后，超时释放锁，b 线程拿到锁后 a 线程继续执行到删除锁操作造成误删）利用 UUID+线程标识 标定当前线程 需要删除锁时进行判断
当 a 要删除锁时到期了，致使线程阻塞，可以使用 lua 脚本保证删除操作的原子性

**问题**
Sentnx 不可重入 不能重复调用
redis 分布式锁无法自动续期
解决：
使用 Redisson 实现分布式锁 可以不断的重入
但是 Redissson 默认释放时间是 30s，如果 30S 加锁业务没有完成，那么在 30-10S 时间进行一次时间延长。一直到锁释放完成
![asset_img](八股-项目/2023-08-28-20-24-10.png)
watchDog 是一个当前线程启动的后台线程，每隔十秒会检查一次，当前客户端在默认时间内一直持有锁就需要进行延长，
Redisss 实现可重入锁，
利用底层中的 voaltile 的 state 变量记录重入状态，每一次加锁都会进行记录+1，每释放一次 state-1 直到 state==0，释放锁
![asset_img](八股-项目/2023-08-28-20-30-26.png)

### 如何防止重复下单

如何判断重复订单：
用户在秒杀页面对同一个秒杀按钮多次点击

1. 使用自定义接口注解，规定在 5 秒内只能访问秒杀接口 5 次
2. 每次的订单请求都会先查询数据库，订单有唯一索引（用户 id+商品 id）,当重复订单落库时数据库会报错
3. 使用分布式锁只有获取到锁的线程才能够下单，未获取到锁则为重复下单
   之后在判断是否

不断查询数据库 性能比较低
需要放在 redis 中使用 set<good_id,userID> 集合保存已经下过商品订单的 userID，当再次下同一个商品时去判断该用户是否存在

### 为什么要异步下单

将消费和生产步骤解耦
将下单部分拆分开来 减少业务耗时
经过 redis 完成预减库存，防止重复消费（分布式锁），和抢单操作后
将下单业务放在消息队列中，异步完成下单过程

### 数据不一致问题

（延迟双删）
问题存在与 MySQL 和 redis 的数据不一致

先更新缓存还是数据库
先更新缓存，那么数据库中可能是旧数据，当缓存失效后查询数据库便可能得到旧数据
先更新数据库，那么缓存中可能是旧数据，当缓存失效后查询数据库就一直是新数据。当更新缓存阻塞时，其他线程依旧会获取旧数据。
但当在并发条件下，频繁进行读多写少环境下，缓存不断更新会出现阻塞等问题使得缓存更新出现问题

在修改数据库时先把缓存删除，当查询缓存发现缓存不存在时从数据库中更新写入缓存。

延迟双删：让写请求去删除两次缓存，从而达到一个刷脏数据的效果，更新完数据库后线程休眠一段时间之后在删除缓存，其中延迟删除的时间应该略大于写操作时间

### 如何保证下单功能和减库存事务的一致性：库存扣减成功但是订单生成失败

使用 Spring 事务@Transactional 更新库存成功后在生成订单 或者使用 lua 脚本.将减库存与生成订单操作组合为一个事务。要么一起成功，要么一起失败。

### 追问：Spring 事务 如何失效何时失效

@Transactional 开启事务，如果执行异常则进行回滚

1. 方法不是 public ，申明式事务基于 AOP 通过代理模式实现，只有 public 方法才能被访问和调用。使用了 final 修饰
2. 方法内部调用没有使用代理对象
3. 类未被 spring 管理
4. 异常被捕获并处理 事务检测不到异常 无法判断是否回滚

### 为什么使用雪花算法

![asset_img](八股-项目/2023-08-30-13-52-10.png)
高并发分布式环境下生成不重复 id，每秒可生成百万个不重复 id。 基于时间戳，以及同一时间戳下序列号自增，基本保证 id 有序递增。 不依赖第三方库或者中间件

### 项目中难点

- 流量削峰问题

### 项目中出现的问题

---

### 如何实现点赞功能

用户不能无限制点赞，不能简单的将数据库数据+1
需求：

- 同一个用户只能点赞一次，再次点击则取消点赞
- 如果当前用户已经点赞，则点赞按钮高亮显示（前端已实现，判断字段 Blog 类的 isLike 属性）
  ![asset_img](八股-项目/2023-09-30-22-06-59.png)

### 对布隆过滤器的理解

解决缓存穿透

### 替换 ThreadLocal

ThreadLocal 在多线程存在大量数据访问时可能会造成内存溢出

- MQ 如何包装重复消费问题：

## RabbitMQ

### 为什么选择 RabbitMQ

相对成熟，社区活跃，吞吐量高，使用 ErLang 开发，性能比较好同时有完善的可视化界面

### 消息队列的优缺点

- 异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量，和系统响应速度
- 应用解耦 - 系统间通过消息通信，不用关心其他系统的处理
- 流量削锋 - 可以通过消息队列长度控制请求量；将短时间内的大量请求分成一个时间段来处理，从而提供了请求的缓冲，提高了系统的并发量。
  缺点：
  提高了系统的复杂度和维护成本，需要考虑消息丢失，重复消费，消息顺序性和一致性的问题系统的复杂度增大

### 消息如何路由

### 如何解决消息的顺序问题

### 高并发情况下接口幂等的解决方案

幂等是指: 多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。
对数据库操作过程中的读取和删除都是天然幂等的，需要注意的是创建和更新操作

- 对数据库使用行锁
- redis 使用分布式锁

### 如何消息不丢失

主要通过持久化机制，确保消息不丢，RabbitMQ 持久化机制分为队列持久化、消息持久化、交换器持久化。

- RabbitMQ 默认不会持久化到硬盘
  要想做到消息持久化，必须满足以下三个条件：
  Exchange 设置持久化
  Queue 设置持久化
  Message 持久化发送：发送消息设置发送模式 deliveryMode=2，代表持久化消息

- 消息 ACK 机制
  使用手动 ACK 机制，处理完成手动调用 MQ 的 ACK 方法通知 MQ 删除消息。

### 什么是延迟队列

RabbitMQ 延迟队列就是存储延迟消息的队列，延迟消息指的就是消息投递到队列后，消费者不能立刻消费，需要等待一段时间，消费者才能消费消息。重点是定时任务
RabbitMQ 原生不支持延迟消息，目前主要通过死信交换机 + 消息 TTL 方案或者使用插件完成

### 死信队列

当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换机中，这个交换机就是 DLX，绑定 DLX 的队列就称之为死信队列。
导致死信的原因：

消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。
消息 TTL 过期。
队列满了，无法再添加。

## 分库分表

- 分库，分表，分库分表
  这三个事儿分别是"只分库不分表"、"只分表不分库"、以及"既分库又分表"。

`分库是将原本的单库拆分为多个库，分表是将原来的单表拆分为多个表。`
将一个大型的数据库拆分成多个小型数据库，每个小型数据库称为一个分片

- 分库
  垂直分库：按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用
  水平分片：通过某个字段根据某种规则将数据分散的到多个库中去，每个分片只包含数据的一部分。其中满足规则的字段为分片键
- 分表：
  垂直分片：将表更具业务分到不同的表中。
  水平分片：将表的字段分到不同的表中

- 应用场景：

  - 分表的场景：数据量过大或者数据库表对应的磁盘文件过大。
  - 分库的场景：当数据库的连接不够客户端使用时，可以考虑分库或读写分离。
  - 分库分表的场景： 高并发写入场景，数据量巨大场景

- 路由表

## 责任链模式

对象的请求会沿着链式方向进行传递，每个处理对象都会检查能否对请求进行处理，能则处理不能继续进行传递，发送请求的对象不知道谁会处理请求，帮助请求者和处理者之间的解耦。

### 布隆过滤器

特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。
但布隆过滤器不能删除

- 原理：
  布隆过滤器通过多个哈希函数对一个数据信息生成多个哈希值将每个 hash 值指向的 bit 位置置 1，将信息映射到 bit 数组中去。
  那么可以想象到若需要映射的数量小，对应到的 bit 数组中的位置分散且不冲突，当映射对象多时，会出现部分 bit 位被多个映射对象覆盖，当需要进行查询的时候，若对象散列的值再过滤器中查到则可能存在（因为会的 bit 位会是对应其他对象的），若不能完全对应到则一定不存在。判断存在会误判，但是判断不存在不会误判
- 一般意义上的布隆过滤器不支持删除。

同样的他存储的数据量和准确性都依赖于布隆过滤器的长度，长度小越容易误判。长度太长也会使得效率降低

> TPS（Transactions Per Second）是一个衡量系统性能的指标，用于表示系统在单位时间内能够处理的事务数量。
> QPS（Queries Per Second）是一个衡量系统负载或性能的指标，用于表示系统在单位时间内处理的查询请求数量。

### 双重校验所提高缓存击穿的性能

当缓存中没有数据的时候，先获取分布式锁，只有一个线程可以成功，在查询数据库之前先用双重校验锁判断一下 ，此时缓存中是否依旧没有数据，确认后再去查数据库，并写入缓存这样其他线程拿到锁尝试去查数据库时回头看到了缓存数据可以提高效率。
